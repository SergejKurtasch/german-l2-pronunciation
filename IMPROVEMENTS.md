# Варианты улучшения точности распознавания фонем

## Проблемы, обнаруженные в текущей реализации

1. **Wav2Vec2Phoneme возвращает буквы вместо фонем** - исправлено: теперь использует vocab.json
2. **Greedy decoding вместо beam search** - исправлено: добавлен beam search
3. **Низкая точность обеих моделей** - требуются дополнительные улучшения

## Реализованные улучшения

### 1. Исправлено декодирование Wav2Vec2Phoneme
- ✅ Теперь использует vocab.json вместо tokenizer.batch_decode()
- ✅ Правильно декодирует IPA фонемы, а не буквы
- ✅ Добавлен beam search для лучшей точности

### 2. Добавлен beam search
- ✅ Beam search для Wav2Vec2Phoneme (как в основной модели)
- ✅ Настраиваемые параметры: BEAM_WIDTH, BEAM_SEARCH_LENGTH_PENALTY

## Дополнительные варианты улучшения

### 1. Использование более крупных моделей

**Вариант A: Wav2Vec2 Large**
```python
# В config.py
MODEL_NAME = "facebook/wav2vec2-large-960h-lv60-self"
# или
MODEL_NAME = "facebook/wav2vec2-xlsr-53"
```
**Плюсы:** Лучшая точность  
**Минусы:** Больше памяти, медленнее

**Вариант B: Fine-tuned модели для немецкого**
```python
# Поиск моделей на Hugging Face:
# https://huggingface.co/models?search=german+phoneme
# https://huggingface.co/models?search=wav2vec2+german
```
**Плюсы:** Специализация на немецком языке  
**Минусы:** Может быть меньше моделей

### 2. Улучшение предобработки аудио

**A. Улучшенная нормализация**
```python
# В config.py
NORMALIZE_METHOD = "adaptive"  # Уже используется
NORMALIZE_COMPRESS_PEAKS = True  # Уже используется
# Можно добавить:
NORMALIZE_TARGET_DBFS = -20  # Целевой уровень громкости
```

**B. Улучшенный VAD (Voice Activity Detection)**
```python
# В config.py
VAD_SILERO_THRESHOLD = 0.05  # Уже очень низкий
# Можно попробовать еще ниже:
VAD_SILERO_THRESHOLD = 0.03
VAD_SILERO_MIN_SILENCE_MS = 50  # Еще меньше
```

**C. Дополнительная фильтрация шума**
```python
# Добавить в audio_normalizer.py:
- Spectral subtraction для удаления шума
- Wiener filtering
- Adaptive noise reduction
```

### 3. Улучшение декодирования

**A. Увеличение beam width**
```python
# В config.py
BEAM_WIDTH = 20  # Увеличить с 10 до 20
BEAM_SEARCH_LENGTH_PENALTY = 0.4  # Уменьшить для более длинных последовательностей
```

**B. Использование Language Model (LM)**
```python
# Добавить языковую модель для постобработки:
- KenLM для немецкого языка
- N-gram модель фонем
- RNN-LM для фонем
```

**C. CTC prefix beam search с LM**
```python
# Более продвинутый алгоритм:
- CTC prefix beam search
- Word-level LM integration
- Phoneme-level LM
```

### 4. Улучшение фильтрации фонем

**A. Настройка порогов уверенности**
```python
# В config.py
CONFIDENCE_THRESHOLD = 0.3  # Снизить для большего количества фонем
# или
CONFIDENCE_THRESHOLD = 0.4  # Повысить для более строгой фильтрации
```

**B. Адаптивная фильтрация**
```python
# В phoneme_filtering.py:
- Динамический порог в зависимости от контекста
- Учет соседних фонем
- Временная фильтрация (удаление слишком коротких сегментов)
```

**C. Whitelist расширение**
```python
# В config.py - добавить больше вариантов фонем:
GERMAN_IPA_PHONEMES += [
    'ɐ', 'aː', 'eː', 'iː', 'oː', 'uː', 'yː',  # Долгие гласные
    'aɪ̯', 'aʊ̯', 'ɔʏ̯',  # Дифтонги
    # и т.д.
]
```

### 5. Улучшение выравнивания (Alignment)

**A. Настройка параметров Needleman-Wunsch**
```python
# В config.py
NW_MATCH_SCORE = 2.0  # Увеличить награду за совпадение
NW_MISMATCH_SCORE = -1.5  # Увеличить штраф за несовпадение
NW_GAP_PENALTY = -0.5  # Уменьшить штраф за пропуски
```

**B. Использование других алгоритмов выравнивания**
```python
# Альтернативы:
- Smith-Waterman (локальное выравнивание)
- Gotoh algorithm (с аффинными штрафами)
- Hidden Markov Model (HMM) alignment
```

**C. Множественное выравнивание**
```python
# Выравнивание с учетом контекста:
- Выравнивание по словам, затем по фонемам
- Учет фонетической близости (например, ɪ и i)
- Временное выравнивание с использованием forced alignment
```

### 6. Постобработка результатов

**A. Фонетическая коррекция**
```python
# Добавить модуль phonetic_correction.py:
- Замена фонетически близких фонем (ɪ → i, ɐ → ə)
- Учет немецких фонетических правил
- Исправление типичных ошибок распознавания
```

**B. Контекстная коррекция**
```python
# Использование контекста для исправления:
- N-gram модели фонем
- Правила ассимиляции в немецком
- Правила редукции гласных
```

### 7. Использование ансамбля моделей

**A. Голосование моделей**
```python
# Объединение результатов нескольких моделей:
- Majority voting
- Weighted voting (по уверенности)
- Stacking (мета-модель)
```

**B. Разные модели для разных задач**
```python
# Специализация:
- Одна модель для гласных
- Другая для согласных
- Третья для дикции
```

### 8. Fine-tuning модели

**A. Дообучение на немецких данных**
```python
# Fine-tuning существующей модели:
- Использовать Common Voice German dataset
- Дообучить на фонемах
- Transfer learning с английской модели
```

**B. Обучение с нуля**
```python
# Если есть достаточно данных:
- Обучение Wav2Vec2 на немецких данных
- Специализированная архитектура для фонем
- Multi-task learning (фонемы + слова)
```

### 9. Улучшение качества аудио

**A. Рекомендации пользователю**
- Использовать качественный микрофон
- Записывать в тихом помещении
- Говорить четко и медленно
- Использовать поп-фильтр

**B. Автоматическая обработка**
```python
# В audio_normalizer.py:
- Автоматическое удаление эха
- Компенсация реверберации
- Улучшение разборчивости речи
```

### 10. Метрики и мониторинг

**A. Добавление метрик качества**
```python
# Отслеживание:
- WER (Word Error Rate) - если есть транскрипция
- PER (Phoneme Error Rate)
- Confidence distribution
- Alignment quality metrics
```

**B. A/B тестирование**
```python
# Сравнение разных подходов:
- Разные модели
- Разные параметры
- Разные алгоритмы декодирования
```

## Рекомендации по приоритетам

### Высокий приоритет (быстрое улучшение)
1. ✅ Исправить декодирование Wav2Vec2Phoneme (сделано)
2. ✅ Добавить beam search (сделано)
3. Настроить параметры фильтрации (CONFIDENCE_THRESHOLD)
4. Улучшить параметры beam search (BEAM_WIDTH, LENGTH_PENALTY)

### Средний приоритет (требует времени)
5. Использовать более крупную модель
6. Улучшить предобработку аудио
7. Добавить фонетическую коррекцию
8. Настроить параметры выравнивания

### Низкий приоритет (долгосрочные проекты)
9. Fine-tuning модели
10. Использование Language Model
11. Ансамбль моделей
12. Обучение с нуля

## Быстрые настройки для тестирования

### Настройка 1: Более агрессивная фильтрация
```python
CONFIDENCE_THRESHOLD = 0.4
BEAM_WIDTH = 15
BEAM_SEARCH_LENGTH_PENALTY = 0.4
```

### Настройка 2: Более мягкая фильтрация
```python
CONFIDENCE_THRESHOLD = 0.3
BEAM_WIDTH = 20
BEAM_SEARCH_LENGTH_PENALTY = 0.3
```

### Настройка 3: Баланс скорости и точности
```python
CONFIDENCE_THRESHOLD = 0.35
BEAM_WIDTH = 10
BEAM_SEARCH_LENGTH_PENALTY = 0.5
```

## Известные ограничения

1. **Модели обучены на разных данных** - могут иметь разные систематические ошибки
2. **Нет Language Model** - фонемы распознаются независимо, без учета контекста
3. **Ограниченная предобработка** - базовая нормализация и VAD
4. **Простое выравнивание** - Needleman-Wunsch без учета фонетической близости
5. **Нет адаптации к говорящему** - модель не адаптируется к голосу пользователя

## Следующие шаги

1. Протестировать исправленное декодирование Wav2Vec2Phoneme
2. Настроить параметры beam search для лучшей точности
3. Рассмотреть добавление Language Model
4. Протестировать более крупные модели
5. Собрать метрики качества для оценки улучшений


