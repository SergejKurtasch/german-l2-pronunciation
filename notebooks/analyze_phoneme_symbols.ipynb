{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phoneme Symbol Analysis from Dictionaries and Model\n",
        "\n",
        "This notebook collects and compares all possible phoneme and special symbol representations from:\n",
        "1. **IPA-Dict-DSL** dictionary\n",
        "2. **MFA Dictionary** dictionary  \n",
        "3. **Phoneme recognition model** (Wav2Vec2)\n",
        "\n",
        "Goal: Identify unique symbols for each source and ensure consistent representation of the same phonemes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports completed successfully\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import Set, Dict, List\n",
        "\n",
        "# Add project path\n",
        "project_root = Path('/Volumes/SSanDisk/SpeechRec-German-diagnostic')\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import modules\n",
        "import config\n",
        "from modules.g2p_module import DSLG2P, LexiconG2P\n",
        "from modules.phoneme_recognition import get_phoneme_recognizer\n",
        "\n",
        "print(\"Imports completed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Character extraction functions created\n"
          ]
        }
      ],
      "source": [
        "def extract_all_characters_from_text(text: str) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extract all unique characters from text, including diacritics and special symbols.\n",
        "    \n",
        "    Args:\n",
        "        text: Text to analyze\n",
        "        \n",
        "    Returns:\n",
        "        Set of all unique characters\n",
        "    \"\"\"\n",
        "    return set(text)\n",
        "\n",
        "\n",
        "def extract_characters_from_dsl_lexicon(dsl_path: Path) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extract all unique characters from IPA-Dict-DSL dictionary.\n",
        "    \n",
        "    Args:\n",
        "        dsl_path: Path to DSL file\n",
        "        \n",
        "    Returns:\n",
        "        Set of all unique characters\n",
        "    \"\"\"\n",
        "    all_chars: Set[str] = set()\n",
        "    \n",
        "    if not dsl_path.exists():\n",
        "        print(f\"⚠ DSL file not found: {dsl_path}\")\n",
        "        return all_chars\n",
        "    \n",
        "    print(f\"Loading characters from DSL dictionary: {dsl_path}\")\n",
        "    \n",
        "    try:\n",
        "        with open(dsl_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.rstrip('\\n\\r')\n",
        "                \n",
        "                # If line without indentation - it's a new word entry\n",
        "                if line and not line.startswith(' ') and not line.startswith('\\t'):\n",
        "                    continue\n",
        "                \n",
        "                # If line with indentation - it's a transcription\n",
        "                elif line and (line.startswith(' ') or line.startswith('\\t')):\n",
        "                    # Extract IPA from [m1]...[/m] tags\n",
        "                    match = re.search(r'\\[m\\d*\\](.*?)\\[/m\\]', line)\n",
        "                    if match:\n",
        "                        raw_transcription = match.group(1).strip()\n",
        "                        if raw_transcription:\n",
        "                            # Add all characters from transcription\n",
        "                            all_chars.update(extract_all_characters_from_text(raw_transcription))\n",
        "        \n",
        "        print(f\"✓ Extracted {len(all_chars)} unique characters from DSL dictionary\")\n",
        "        return all_chars\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading DSL dictionary: {e}\")\n",
        "        return all_chars\n",
        "\n",
        "\n",
        "def extract_characters_from_mfa_lexicon(mfa_path: Path) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extract all unique characters from MFA dictionary.\n",
        "    \n",
        "    Args:\n",
        "        mfa_path: Path to MFA dictionary\n",
        "        \n",
        "    Returns:\n",
        "        Set of all unique characters\n",
        "    \"\"\"\n",
        "    all_chars: Set[str] = set()\n",
        "    \n",
        "    if not mfa_path.exists():\n",
        "        print(f\"⚠ MFA file not found: {mfa_path}\")\n",
        "        return all_chars\n",
        "    \n",
        "    print(f\"Loading characters from MFA dictionary: {mfa_path}\")\n",
        "    \n",
        "    try:\n",
        "        with open(mfa_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 2:\n",
        "                    # Process all parts after the word (phonemes)\n",
        "                    for part in parts[1:]:\n",
        "                        try:\n",
        "                            # Skip numbers (probabilities)\n",
        "                            float(part)\n",
        "                            continue\n",
        "                        except ValueError:\n",
        "                            # This is a phoneme - add all its characters\n",
        "                            all_chars.update(extract_all_characters_from_text(part))\n",
        "        \n",
        "        print(f\"✓ Extracted {len(all_chars)} unique characters from MFA dictionary\")\n",
        "        return all_chars\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading MFA dictionary: {e}\")\n",
        "        return all_chars\n",
        "\n",
        "\n",
        "def extract_characters_from_model_vocab(model_recognizer) -> Set[str]:\n",
        "    \"\"\"\n",
        "    Extract all unique characters from model vocabulary.\n",
        "    \n",
        "    Args:\n",
        "        model_recognizer: PhonemeRecognizer instance\n",
        "        \n",
        "    Returns:\n",
        "        Set of all unique characters\n",
        "    \"\"\"\n",
        "    all_chars: Set[str] = set()\n",
        "    \n",
        "    try:\n",
        "        vocab = model_recognizer.get_vocab()\n",
        "        print(f\"Loading characters from model: {model_recognizer.model_name}\")\n",
        "        print(f\"Model vocabulary size: {len(vocab)}\")\n",
        "        \n",
        "        # Special tokens to exclude\n",
        "        skip_tokens = {\n",
        "            '[PAD]', '[UNK]', '<pad>', '<unk>', '<blank>', '[BLANK]', \n",
        "            '<s>', '</s>', '<|endoftext|>', '|', 'h#', 'spn', '',\n",
        "            '<sos>', '<eos>', '[CLS]', '[SEP]', '[MASK]'\n",
        "        }\n",
        "        \n",
        "        for token in vocab.keys():\n",
        "            # Skip special tokens\n",
        "            if token in skip_tokens:\n",
        "                continue\n",
        "            # Skip tokens that look like service tokens\n",
        "            if token.startswith('<') and token.endswith('>'):\n",
        "                continue\n",
        "            if token.startswith('[') and token.endswith(']'):\n",
        "                continue\n",
        "            \n",
        "            # Add all characters from token\n",
        "            all_chars.update(extract_all_characters_from_text(token))\n",
        "        \n",
        "        print(f\"✓ Extracted {len(all_chars)} unique characters from model\")\n",
        "        return all_chars\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error loading model vocabulary: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return all_chars\n",
        "\n",
        "\n",
        "print(\"Character extraction functions created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "1. LOADING CHARACTERS FROM IPA-Dict-DSL DICTIONARY\n",
            "================================================================================\n",
            "Loading characters from DSL dictionary: /Volumes/SSanDisk/SpeechRec-German-diagnostic/data/dictionaries/de_ipa.dsl\n",
            "✓ Extracted 97 unique characters from DSL dictionary\n",
            "Total unique characters: 97\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load characters from IPA-Dict-DSL dictionary\n",
        "print(\"=\" * 80)\n",
        "print(\"1. LOADING CHARACTERS FROM IPA-Dict-DSL DICTIONARY\")\n",
        "print(\"=\" * 80)\n",
        "dsl_chars = extract_characters_from_dsl_lexicon(config.IPA_DSL_LEXICON_PATH)\n",
        "print(f\"Total unique characters: {len(dsl_chars)}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "2. LOADING CHARACTERS FROM MFA DICTIONARY\n",
            "================================================================================\n",
            "Loading characters from MFA dictionary: /Volumes/SSanDisk/SpeechRec-German-diagnostic/data/dictionaries/german_mfa.dict\n",
            "✓ Extracted 42 unique characters from MFA dictionary\n",
            "Total unique characters: 42\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load characters from MFA dictionary\n",
        "print(\"=\" * 80)\n",
        "print(\"2. LOADING CHARACTERS FROM MFA DICTIONARY\")\n",
        "print(\"=\" * 80)\n",
        "mfa_chars = extract_characters_from_mfa_lexicon(config.MFA_GERMAN_LEXICON_PATH)\n",
        "print(f\"Total unique characters: {len(mfa_chars)}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "3. LOADING CHARACTERS FROM PHONEME RECOGNITION MODEL\n",
            "================================================================================\n",
            "Loading characters from model: facebook/wav2vec2-xlsr-53-espeak-cv-ft\n",
            "Model vocabulary size: 392\n",
            "✓ Extracted 106 unique characters from model\n",
            "Total unique characters: 106\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load characters from phoneme recognition model\n",
        "print(\"=\" * 80)\n",
        "print(\"3. LOADING CHARACTERS FROM PHONEME RECOGNITION MODEL\")\n",
        "print(\"=\" * 80)\n",
        "try:\n",
        "    model_recognizer = get_phoneme_recognizer(\n",
        "        model_name=config.MODEL_NAME,\n",
        "        device=config.MODEL_DEVICE if config.MODEL_DEVICE != \"auto\" else None\n",
        "    )\n",
        "    model_chars = extract_characters_from_model_vocab(model_recognizer)\n",
        "    print(f\"Total unique characters: {len(model_chars)}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error loading model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    model_chars: Set[str] = set()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "4. CHARACTER COMPARISON AND ANALYSIS\n",
            "================================================================================\n",
            "Total unique characters across all sources: 146\n",
            "\n",
            "Characters present in all three sources: 38\n",
            "Characters common to DSL and MFA: 39\n",
            "Characters common to DSL and model: 57\n",
            "Characters common to MFA and model: 41\n",
            "\n",
            "Characters unique to DSL: 39\n",
            "Characters unique to MFA: 0\n",
            "Characters unique to model: 46\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compare and analyze characters\n",
        "print(\"=\" * 80)\n",
        "print(\"4. CHARACTER COMPARISON AND ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Union of all characters\n",
        "all_chars = dsl_chars | mfa_chars | model_chars\n",
        "print(f\"Total unique characters across all sources: {len(all_chars)}\")\n",
        "print()\n",
        "\n",
        "# Common characters\n",
        "common_all = dsl_chars & mfa_chars & model_chars\n",
        "common_dsl_mfa = dsl_chars & mfa_chars\n",
        "common_dsl_model = dsl_chars & model_chars\n",
        "common_mfa_model = mfa_chars & model_chars\n",
        "\n",
        "print(f\"Characters present in all three sources: {len(common_all)}\")\n",
        "print(f\"Characters common to DSL and MFA: {len(common_dsl_mfa)}\")\n",
        "print(f\"Characters common to DSL and model: {len(common_dsl_model)}\")\n",
        "print(f\"Characters common to MFA and model: {len(common_mfa_model)}\")\n",
        "print()\n",
        "\n",
        "# Unique characters for each source\n",
        "only_dsl = dsl_chars - mfa_chars - model_chars\n",
        "only_mfa = mfa_chars - dsl_chars - model_chars\n",
        "only_model = model_chars - dsl_chars - mfa_chars\n",
        "\n",
        "print(f\"Characters unique to DSL: {len(only_dsl)}\")\n",
        "print(f\"Characters unique to MFA: {len(only_mfa)}\")\n",
        "print(f\"Characters unique to model: {len(only_model)}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "5. DETAILED CHARACTER OUTPUT\n",
            "================================================================================\n",
            "\n",
            "DSL Dictionary (97 characters):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "IPA Vowels (15):\n",
            "    1. 'a' (U+0061)\n",
            "    2. 'e' (U+0065)\n",
            "    3. 'i' (U+0069)\n",
            "    4. 'o' (U+006F)\n",
            "    5. 'u' (U+0075)\n",
            "    6. 'y' (U+0079)\n",
            "    7. 'ø' (U+00F8)\n",
            "    8. 'œ' (U+0153)\n",
            "    9. 'ɐ' (U+0250)\n",
            "   10. 'ɔ' (U+0254)\n",
            "   11. 'ə' (U+0259)\n",
            "   12. 'ɛ' (U+025B)\n",
            "   13. 'ɪ' (U+026A)\n",
            "   14. 'ʊ' (U+028A)\n",
            "   15. 'ʏ' (U+028F)\n",
            "\n",
            "IPA Consonants (21):\n",
            "    1. 'b' (U+0062)\n",
            "    2. 'd' (U+0064)\n",
            "    3. 'f' (U+0066)\n",
            "    4. 'g' (U+0067)\n",
            "    5. 'h' (U+0068)\n",
            "    6. 'k' (U+006B)\n",
            "    7. 'l' (U+006C)\n",
            "    8. 'm' (U+006D)\n",
            "    9. 'n' (U+006E)\n",
            "   10. 'p' (U+0070)\n",
            "   11. 'r' (U+0072)\n",
            "   12. 's' (U+0073)\n",
            "   13. 't' (U+0074)\n",
            "   14. 'v' (U+0076)\n",
            "   15. 'x' (U+0078)\n",
            "   16. 'z' (U+007A)\n",
            "   17. 'ç' (U+00E7)\n",
            "   18. 'ŋ' (U+014B)\n",
            "   19. 'ʁ' (U+0281)\n",
            "   20. 'ʃ' (U+0283)\n",
            "   21. 'ʒ' (U+0292)\n",
            "\n",
            "Diacritical Marks (6):\n",
            "    1. '̃' (U+0303)\n",
            "    2. '̆' (U+0306)\n",
            "    3. '̍' (U+030D)\n",
            "    4. '̥' (U+0325)\n",
            "    5. '̩' (U+0329)\n",
            "    6. '͡' (U+0361)\n",
            "\n",
            "Suprasegmental Marks (5):\n",
            "    1. 'ˈ' (U+02C8)\n",
            "    2. 'ˌ' (U+02CC)\n",
            "    3. 'ː' (U+02D0)\n",
            "    4. '̯' (U+032F)\n",
            "    5. '͜' (U+035C)\n",
            "\n",
            "ASCII Characters (26):\n",
            "    1. ''' (U+0027)\n",
            "    2. '(' (U+0028)\n",
            "    3. ')' (U+0029)\n",
            "    4. '.' (U+002E)\n",
            "    5. '/' (U+002F)\n",
            "    6. ':' (U+003A)\n",
            "    7. '?' (U+003F)\n",
            "    8. 'A' (U+0041)\n",
            "    9. 'C' (U+0043)\n",
            "   10. 'D' (U+0044)\n",
            "   11. 'E' (U+0045)\n",
            "   12. 'F' (U+0046)\n",
            "   13. 'N' (U+004E)\n",
            "   14. 'O' (U+004F)\n",
            "   15. 'Q' (U+0051)\n",
            "   16. 'R' (U+0052)\n",
            "   17. 'S' (U+0053)\n",
            "   18. 'T' (U+0054)\n",
            "   19. 'U' (U+0055)\n",
            "   20. '[' (U+005B)\n",
            "   21. '\\' (U+005C)\n",
            "   22. ']' (U+005D)\n",
            "   23. 'j' (U+006A)\n",
            "   24. 'w' (U+0077)\n",
            "   25. '|' (U+007C)\n",
            "   26. '~' (U+007E)\n",
            "\n",
            "Other Symbols (24):\n",
            "    1. 'ã' (U+00E3)\n",
            "    2. 'æ' (U+00E6)\n",
            "    3. 'õ' (U+00F5)\n",
            "    4. 'ĭ' (U+012D)\n",
            "    5. 'ɑ' (U+0251)\n",
            "    6. 'ɕ' (U+0255)\n",
            "    7. 'ɘ' (U+0258)\n",
            "    8. 'ɡ' (U+0261)\n",
            "    9. 'ɱ' (U+0271)\n",
            "   10. 'ɽ' (U+027D)\n",
            "   11. 'ɾ' (U+027E)\n",
            "   12. 'ʀ' (U+0280)\n",
            "   13. 'ʋ' (U+028B)\n",
            "   14. 'ʔ' (U+0294)\n",
            "   15. 'ʧ' (U+02A7)\n",
            "   16. 'ʰ' (U+02B0)\n",
            "   17. 'ˀ' (U+02C0)\n",
            "   18. 'ˑ' (U+02D1)\n",
            "   19. 'θ' (U+03B8)\n",
            "   20. 'χ' (U+03C7)\n",
            "   21. 'ᵻ' (U+1D7B)\n",
            "   22. '​' (U+200B)\n",
            "   23. '…' (U+2026)\n",
            "   24. '⁠' (U+2060)\n",
            "\n",
            "MFA Dictionary (42 characters):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "IPA Vowels (15):\n",
            "    1. 'a' (U+0061)\n",
            "    2. 'e' (U+0065)\n",
            "    3. 'i' (U+0069)\n",
            "    4. 'o' (U+006F)\n",
            "    5. 'u' (U+0075)\n",
            "    6. 'y' (U+0079)\n",
            "    7. 'ø' (U+00F8)\n",
            "    8. 'œ' (U+0153)\n",
            "    9. 'ɐ' (U+0250)\n",
            "   10. 'ɔ' (U+0254)\n",
            "   11. 'ə' (U+0259)\n",
            "   12. 'ɛ' (U+025B)\n",
            "   13. 'ɪ' (U+026A)\n",
            "   14. 'ʊ' (U+028A)\n",
            "   15. 'ʏ' (U+028F)\n",
            "\n",
            "IPA Consonants (18):\n",
            "    1. 'b' (U+0062)\n",
            "    2. 'd' (U+0064)\n",
            "    3. 'f' (U+0066)\n",
            "    4. 'h' (U+0068)\n",
            "    5. 'k' (U+006B)\n",
            "    6. 'l' (U+006C)\n",
            "    7. 'm' (U+006D)\n",
            "    8. 'n' (U+006E)\n",
            "    9. 'p' (U+0070)\n",
            "   10. 's' (U+0073)\n",
            "   11. 't' (U+0074)\n",
            "   12. 'v' (U+0076)\n",
            "   13. 'x' (U+0078)\n",
            "   14. 'z' (U+007A)\n",
            "   15. 'ç' (U+00E7)\n",
            "   16. 'ŋ' (U+014B)\n",
            "   17. 'ʁ' (U+0281)\n",
            "   18. 'ʃ' (U+0283)\n",
            "\n",
            "Diacritical Marks (1):\n",
            "    1. '̩' (U+0329)\n",
            "\n",
            "Suprasegmental Marks (1):\n",
            "    1. 'ː' (U+02D0)\n",
            "\n",
            "ASCII Characters (3):\n",
            "    1. 'c' (U+0063)\n",
            "    2. 'j' (U+006A)\n",
            "    3. 'w' (U+0077)\n",
            "\n",
            "Other Symbols (4):\n",
            "    1. 'ɟ' (U+025F)\n",
            "    2. 'ɡ' (U+0261)\n",
            "    3. 'ɲ' (U+0272)\n",
            "    4. 'ʰ' (U+02B0)\n",
            "\n",
            "Model (106 characters):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "IPA Vowels (14):\n",
            "    1. 'a' (U+0061)\n",
            "    2. 'e' (U+0065)\n",
            "    3. 'i' (U+0069)\n",
            "    4. 'o' (U+006F)\n",
            "    5. 'u' (U+0075)\n",
            "    6. 'y' (U+0079)\n",
            "    7. 'ø' (U+00F8)\n",
            "    8. 'œ' (U+0153)\n",
            "    9. 'ɐ' (U+0250)\n",
            "   10. 'ɔ' (U+0254)\n",
            "   11. 'ə' (U+0259)\n",
            "   12. 'ɛ' (U+025B)\n",
            "   13. 'ɪ' (U+026A)\n",
            "   14. 'ʊ' (U+028A)\n",
            "\n",
            "IPA Consonants (20):\n",
            "    1. 'b' (U+0062)\n",
            "    2. 'd' (U+0064)\n",
            "    3. 'f' (U+0066)\n",
            "    4. 'h' (U+0068)\n",
            "    5. 'k' (U+006B)\n",
            "    6. 'l' (U+006C)\n",
            "    7. 'm' (U+006D)\n",
            "    8. 'n' (U+006E)\n",
            "    9. 'p' (U+0070)\n",
            "   10. 'r' (U+0072)\n",
            "   11. 's' (U+0073)\n",
            "   12. 't' (U+0074)\n",
            "   13. 'v' (U+0076)\n",
            "   14. 'x' (U+0078)\n",
            "   15. 'z' (U+007A)\n",
            "   16. 'ç' (U+00E7)\n",
            "   17. 'ŋ' (U+014B)\n",
            "   18. 'ʁ' (U+0281)\n",
            "   19. 'ʃ' (U+0283)\n",
            "   20. 'ʒ' (U+0292)\n",
            "\n",
            "Diacritical Marks (6):\n",
            "    1. '̃' (U+0303)\n",
            "    2. '̊' (U+030A)\n",
            "    3. '̝' (U+031D)\n",
            "    4. '̞' (U+031E)\n",
            "    5. '̩' (U+0329)\n",
            "    6. '̪' (U+032A)\n",
            "\n",
            "Suprasegmental Marks (1):\n",
            "    1. 'ː' (U+02D0)\n",
            "\n",
            "ASCII Characters (18):\n",
            "    1. '\"' (U+0022)\n",
            "    2. '.' (U+002E)\n",
            "    3. '1' (U+0031)\n",
            "    4. '2' (U+0032)\n",
            "    5. '4' (U+0034)\n",
            "    6. '5' (U+0035)\n",
            "    7. ':' (U+003A)\n",
            "    8. '?' (U+003F)\n",
            "    9. 'N' (U+004E)\n",
            "   10. 'S' (U+0053)\n",
            "   11. 'X' (U+0058)\n",
            "   12. 'Z' (U+005A)\n",
            "   13. '[' (U+005B)\n",
            "   14. '^' (U+005E)\n",
            "   15. 'c' (U+0063)\n",
            "   16. 'j' (U+006A)\n",
            "   17. 'q' (U+0071)\n",
            "   18. 'w' (U+0077)\n",
            "\n",
            "Other Symbols (47):\n",
            "    1. 'ä' (U+00E4)\n",
            "    2. 'æ' (U+00E6)\n",
            "    3. 'ð' (U+00F0)\n",
            "    4. 'ħ' (U+0127)\n",
            "    5. 'ũ' (U+0169)\n",
            "    6. 'ɑ' (U+0251)\n",
            "    7. 'ɒ' (U+0252)\n",
            "    8. 'ɕ' (U+0255)\n",
            "    9. 'ɖ' (U+0256)\n",
            "   10. 'ɚ' (U+025A)\n",
            "   11. 'ɜ' (U+025C)\n",
            "   12. 'ɟ' (U+025F)\n",
            "   13. 'ɡ' (U+0261)\n",
            "   14. 'ɣ' (U+0263)\n",
            "   15. 'ɨ' (U+0268)\n",
            "   16. 'ɫ' (U+026B)\n",
            "   17. 'ɬ' (U+026C)\n",
            "   18. 'ɭ' (U+026D)\n",
            "   19. 'ɯ' (U+026F)\n",
            "   20. 'ɲ' (U+0272)\n",
            "   21. 'ɳ' (U+0273)\n",
            "   22. 'ɴ' (U+0274)\n",
            "   23. 'ɵ' (U+0275)\n",
            "   24. 'ɸ' (U+0278)\n",
            "   25. 'ɹ' (U+0279)\n",
            "   26. 'ɻ' (U+027B)\n",
            "   27. 'ɽ' (U+027D)\n",
            "   28. 'ɾ' (U+027E)\n",
            "   29. 'ʂ' (U+0282)\n",
            "   30. 'ʈ' (U+0288)\n",
            "   31. 'ʉ' (U+0289)\n",
            "   32. 'ʋ' (U+028B)\n",
            "   33. 'ʌ' (U+028C)\n",
            "   34. 'ʎ' (U+028E)\n",
            "   35. 'ʐ' (U+0290)\n",
            "   36. 'ʑ' (U+0291)\n",
            "   37. 'ʔ' (U+0294)\n",
            "   38. 'ʕ' (U+0295)\n",
            "   39. 'ʝ' (U+029D)\n",
            "   40. 'ʰ' (U+02B0)\n",
            "   41. 'ʲ' (U+02B2)\n",
            "   42. 'ˤ' (U+02E4)\n",
            "   43. 'β' (U+03B2)\n",
            "   44. 'θ' (U+03B8)\n",
            "   45. 'χ' (U+03C7)\n",
            "   46. 'ᵝ' (U+1D5D)\n",
            "   47. 'ᵻ' (U+1D7B)\n"
          ]
        }
      ],
      "source": [
        "# Detailed character output\n",
        "print(\"=\" * 80)\n",
        "print(\"5. DETAILED CHARACTER OUTPUT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "def print_char_set(name: str, char_set: Set[str], max_display: int = 100) -> None:\n",
        "    \"\"\"Print a set of characters with their Unicode codes.\"\"\"\n",
        "    if not char_set:\n",
        "        print(f\"\\n{name}: (empty)\")\n",
        "        return\n",
        "    \n",
        "    sorted_chars = sorted(char_set)\n",
        "    print(f\"\\n{name} ({len(char_set)} characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Group by categories\n",
        "    ipa_vowels: List[str] = []\n",
        "    ipa_consonants: List[str] = []\n",
        "    ipa_diacritics: List[str] = []\n",
        "    ipa_suprasegmentals: List[str] = []\n",
        "    ipa_other: List[str] = []\n",
        "    ascii_chars: List[str] = []\n",
        "    \n",
        "    for char in sorted_chars:\n",
        "        # Get Unicode code\n",
        "        unicode_code = ord(char)\n",
        "        char_info = f\"'{char}' (U+{unicode_code:04X})\"\n",
        "        \n",
        "        # Classify characters\n",
        "        if char in 'aeiouyøœɛɔɪʊʏəɐ':\n",
        "            ipa_vowels.append(char_info)\n",
        "        elif char in 'pbtdkgfvszʃʒçxhmnlrʁŋ':\n",
        "            ipa_consonants.append(char_info)\n",
        "        elif char in 'ːˌˈ̯͜':\n",
        "            ipa_suprasegmentals.append(char_info)\n",
        "        elif 0x0300 <= ord(char) <= 0x036F:  # Combining diacritics\n",
        "            ipa_diacritics.append(char_info)\n",
        "        elif char.isascii() and char.isprintable():\n",
        "            ascii_chars.append(char_info)\n",
        "        else:\n",
        "            ipa_other.append(char_info)\n",
        "    \n",
        "    # Print by categories\n",
        "    if ipa_vowels:\n",
        "        print(f\"\\nIPA Vowels ({len(ipa_vowels)}):\")\n",
        "        for i, char_info in enumerate(ipa_vowels[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ipa_vowels) > max_display:\n",
        "            print(f\"  ... and {len(ipa_vowels) - max_display} more characters\")\n",
        "    \n",
        "    if ipa_consonants:\n",
        "        print(f\"\\nIPA Consonants ({len(ipa_consonants)}):\")\n",
        "        for i, char_info in enumerate(ipa_consonants[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ipa_consonants) > max_display:\n",
        "            print(f\"  ... and {len(ipa_consonants) - max_display} more characters\")\n",
        "    \n",
        "    if ipa_diacritics:\n",
        "        print(f\"\\nDiacritical Marks ({len(ipa_diacritics)}):\")\n",
        "        for i, char_info in enumerate(ipa_diacritics[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ipa_diacritics) > max_display:\n",
        "            print(f\"  ... and {len(ipa_diacritics) - max_display} more characters\")\n",
        "    \n",
        "    if ipa_suprasegmentals:\n",
        "        print(f\"\\nSuprasegmental Marks ({len(ipa_suprasegmentals)}):\")\n",
        "        for i, char_info in enumerate(ipa_suprasegmentals[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ipa_suprasegmentals) > max_display:\n",
        "            print(f\"  ... and {len(ipa_suprasegmentals) - max_display} more characters\")\n",
        "    \n",
        "    if ascii_chars:\n",
        "        print(f\"\\nASCII Characters ({len(ascii_chars)}):\")\n",
        "        for i, char_info in enumerate(ascii_chars[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ascii_chars) > max_display:\n",
        "            print(f\"  ... and {len(ascii_chars) - max_display} more characters\")\n",
        "    \n",
        "    if ipa_other:\n",
        "        print(f\"\\nOther Symbols ({len(ipa_other)}):\")\n",
        "        for i, char_info in enumerate(ipa_other[:max_display], 1):\n",
        "            print(f\"  {i:3d}. {char_info}\")\n",
        "        if len(ipa_other) > max_display:\n",
        "            print(f\"  ... and {len(ipa_other) - max_display} more characters\")\n",
        "\n",
        "\n",
        "# Print all characters from each source\n",
        "print_char_set(\"DSL Dictionary\", dsl_chars)\n",
        "print_char_set(\"MFA Dictionary\", mfa_chars)\n",
        "print_char_set(\"Model\", model_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "6. UNIQUE CHARACTERS FOR EACH SOURCE\n",
            "================================================================================\n",
            "\n",
            "Only in DSL dictionary (39 characters):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "IPA Consonants (1):\n",
            "    1. 'g' (U+0067)\n",
            "\n",
            "Diacritical Marks (4):\n",
            "    1. '̆' (U+0306)\n",
            "    2. '̍' (U+030D)\n",
            "    3. '̥' (U+0325)\n",
            "    4. '͡' (U+0361)\n",
            "\n",
            "Suprasegmental Marks (4):\n",
            "    1. 'ˈ' (U+02C8)\n",
            "    2. 'ˌ' (U+02CC)\n",
            "    3. '̯' (U+032F)\n",
            "    4. '͜' (U+035C)\n",
            "\n",
            "ASCII Characters (18):\n",
            "    1. ''' (U+0027)\n",
            "    2. '(' (U+0028)\n",
            "    3. ')' (U+0029)\n",
            "    4. '/' (U+002F)\n",
            "    5. 'A' (U+0041)\n",
            "    6. 'C' (U+0043)\n",
            "    7. 'D' (U+0044)\n",
            "    8. 'E' (U+0045)\n",
            "    9. 'F' (U+0046)\n",
            "   10. 'O' (U+004F)\n",
            "   11. 'Q' (U+0051)\n",
            "   12. 'R' (U+0052)\n",
            "   13. 'T' (U+0054)\n",
            "   14. 'U' (U+0055)\n",
            "   15. '\\' (U+005C)\n",
            "   16. ']' (U+005D)\n",
            "   17. '|' (U+007C)\n",
            "   18. '~' (U+007E)\n",
            "\n",
            "Other Symbols (12):\n",
            "    1. 'ã' (U+00E3)\n",
            "    2. 'õ' (U+00F5)\n",
            "    3. 'ĭ' (U+012D)\n",
            "    4. 'ɘ' (U+0258)\n",
            "    5. 'ɱ' (U+0271)\n",
            "    6. 'ʀ' (U+0280)\n",
            "    7. 'ʧ' (U+02A7)\n",
            "    8. 'ˀ' (U+02C0)\n",
            "    9. 'ˑ' (U+02D1)\n",
            "   10. '​' (U+200B)\n",
            "   11. '…' (U+2026)\n",
            "   12. '⁠' (U+2060)\n",
            "\n",
            "Only in MFA dictionary: (empty)\n",
            "\n",
            "Only in model (46 characters):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Diacritical Marks (4):\n",
            "    1. '̊' (U+030A)\n",
            "    2. '̝' (U+031D)\n",
            "    3. '̞' (U+031E)\n",
            "    4. '̪' (U+032A)\n",
            "\n",
            "ASCII Characters (9):\n",
            "    1. '\"' (U+0022)\n",
            "    2. '1' (U+0031)\n",
            "    3. '2' (U+0032)\n",
            "    4. '4' (U+0034)\n",
            "    5. '5' (U+0035)\n",
            "    6. 'X' (U+0058)\n",
            "    7. 'Z' (U+005A)\n",
            "    8. '^' (U+005E)\n",
            "    9. 'q' (U+0071)\n",
            "\n",
            "Other Symbols (33):\n",
            "    1. 'ä' (U+00E4)\n",
            "    2. 'ð' (U+00F0)\n",
            "    3. 'ħ' (U+0127)\n",
            "    4. 'ũ' (U+0169)\n",
            "    5. 'ɒ' (U+0252)\n",
            "    6. 'ɖ' (U+0256)\n",
            "    7. 'ɚ' (U+025A)\n",
            "    8. 'ɜ' (U+025C)\n",
            "    9. 'ɣ' (U+0263)\n",
            "   10. 'ɨ' (U+0268)\n",
            "   11. 'ɫ' (U+026B)\n",
            "   12. 'ɬ' (U+026C)\n",
            "   13. 'ɭ' (U+026D)\n",
            "   14. 'ɯ' (U+026F)\n",
            "   15. 'ɳ' (U+0273)\n",
            "   16. 'ɴ' (U+0274)\n",
            "   17. 'ɵ' (U+0275)\n",
            "   18. 'ɸ' (U+0278)\n",
            "   19. 'ɹ' (U+0279)\n",
            "   20. 'ɻ' (U+027B)\n",
            "   21. 'ʂ' (U+0282)\n",
            "   22. 'ʈ' (U+0288)\n",
            "   23. 'ʉ' (U+0289)\n",
            "   24. 'ʌ' (U+028C)\n",
            "   25. 'ʎ' (U+028E)\n",
            "   26. 'ʐ' (U+0290)\n",
            "   27. 'ʑ' (U+0291)\n",
            "   28. 'ʕ' (U+0295)\n",
            "   29. 'ʝ' (U+029D)\n",
            "   30. 'ʲ' (U+02B2)\n",
            "   31. 'ˤ' (U+02E4)\n",
            "   32. 'β' (U+03B2)\n",
            "   33. 'ᵝ' (U+1D5D)\n"
          ]
        }
      ],
      "source": [
        "# Unique characters for each source\n",
        "print(\"=\" * 80)\n",
        "print(\"6. UNIQUE CHARACTERS FOR EACH SOURCE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print_char_set(\"Only in DSL dictionary\", only_dsl)\n",
        "print_char_set(\"Only in MFA dictionary\", only_mfa)\n",
        "print_char_set(\"Only in model\", only_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "7. ANALYSIS AND RECOMMENDATIONS\n",
            "================================================================================\n",
            "\n",
            "Potential encoding issues:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Variants of symbol 'a':\n",
            "  'a' (U+0061) - found in: DSL, MFA, Model\n",
            "  'ɑ' (U+0251) - found in: DSL, Model\n",
            "  'ɐ' (U+0250) - found in: DSL, MFA, Model\n",
            "\n",
            "Variants of symbol 'g':\n",
            "  'g' (U+0067) - found in: DSL\n",
            "  'ɡ' (U+0261) - found in: DSL, MFA, Model\n",
            "\n",
            "Variants of symbol 'r':\n",
            "  'r' (U+0072) - found in: DSL, Model\n",
            "  'ɾ' (U+027E) - found in: DSL, Model\n",
            "  'ʁ' (U+0281) - found in: DSL, MFA, Model\n",
            "\n",
            "Variants of symbol 'e':\n",
            "  'e' (U+0065) - found in: DSL, MFA, Model\n",
            "  'ɛ' (U+025B) - found in: DSL, MFA, Model\n",
            "  'ɜ' (U+025C) - found in: Model\n",
            "\n",
            "Variants of symbol 'i':\n",
            "  'i' (U+0069) - found in: DSL, MFA, Model\n",
            "  'ɪ' (U+026A) - found in: DSL, MFA, Model\n",
            "\n",
            "Variants of symbol 'u':\n",
            "  'u' (U+0075) - found in: DSL, MFA, Model\n",
            "  'ʊ' (U+028A) - found in: DSL, MFA, Model\n",
            "\n",
            "Variants of symbol 'o':\n",
            "  'o' (U+006F) - found in: DSL, MFA, Model\n",
            "  'ɔ' (U+0254) - found in: DSL, MFA, Model\n",
            "\n",
            "\n",
            "Diacritical and special marks:\n",
            "--------------------------------------------------------------------------------\n",
            "Found 12 diacritical marks:\n",
            "  '̃' (U+0303) - found in: DSL, Model\n",
            "  '̆' (U+0306) - found in: DSL\n",
            "  '̊' (U+030A) - found in: Model\n",
            "  '̍' (U+030D) - found in: DSL\n",
            "  '̝' (U+031D) - found in: Model\n",
            "  '̞' (U+031E) - found in: Model\n",
            "  '̥' (U+0325) - found in: DSL\n",
            "  '̩' (U+0329) - found in: DSL, MFA, Model\n",
            "  '̪' (U+032A) - found in: Model\n",
            "  '̯' (U+032F) - found in: DSL\n",
            "  '͜' (U+035C) - found in: DSL\n",
            "  '͡' (U+0361) - found in: DSL\n",
            "\n",
            "Found 5 suprasegmental marks:\n",
            "  'ˈ' (U+02C8) - found in: DSL\n",
            "  'ˌ' (U+02CC) - found in: DSL\n",
            "  'ː' (U+02D0) - found in: DSL, MFA, Model\n",
            "  '̯' (U+032F) - found in: DSL\n",
            "  '͜' (U+035C) - found in: DSL\n",
            "\n",
            "\n",
            "Recommendations:\n",
            "--------------------------------------------------------------------------------\n",
            "1. Unique symbols that are not found elsewhere:\n",
            "   - DSL: 39 symbols - decide: ignore or map\n",
            "   - Model: 46 symbols - decide: ignore or map\n",
            "\n",
            "2. Symbol variants (e.g., different 'a', 'g', 'r'):\n",
            "   - Need to decide which variants to use for normalization\n",
            "   - Important: do not simplify close but different phonemes\n",
            "\n",
            "3. Special symbols (diacritics, suprasegmentals):\n",
            "   - Decide how to handle: keep or remove\n",
            "   - Note that some may be important for phoneme distinction\n"
          ]
        }
      ],
      "source": [
        "# Analysis of potential issues and recommendations\n",
        "print(\"=\" * 80)\n",
        "print(\"7. ANALYSIS AND RECOMMENDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check for similar symbols that may be different variants of the same phoneme\n",
        "print(\"\\nPotential encoding issues:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Check symbol variants (e.g., different variants of 'a', 'g', 'r')\n",
        "variants_to_check = {\n",
        "    'a': ['a', 'ɑ', 'ɐ'],\n",
        "    'g': ['g', 'ɡ'],\n",
        "    'r': ['r', 'ɾ', 'ʁ'],\n",
        "    'e': ['e', 'ɛ', 'ɜ'],\n",
        "    'i': ['i', 'ɪ'],\n",
        "    'u': ['u', 'ʊ'],\n",
        "    'o': ['o', 'ɔ'],\n",
        "}\n",
        "\n",
        "for base_char, variants in variants_to_check.items():\n",
        "    found_variants = []\n",
        "    for variant in variants:\n",
        "        if variant in all_chars:\n",
        "            sources = []\n",
        "            if variant in dsl_chars:\n",
        "                sources.append(\"DSL\")\n",
        "            if variant in mfa_chars:\n",
        "                sources.append(\"MFA\")\n",
        "            if variant in model_chars:\n",
        "                sources.append(\"Model\")\n",
        "            found_variants.append((variant, sources))\n",
        "    \n",
        "    if len(found_variants) > 1:\n",
        "        print(f\"\\nVariants of symbol '{base_char}':\")\n",
        "        for variant, sources in found_variants:\n",
        "            print(f\"  '{variant}' (U+{ord(variant):04X}) - found in: {', '.join(sources)}\")\n",
        "\n",
        "# Check diacritical marks\n",
        "print(\"\\n\\nDiacritical and special marks:\")\n",
        "print(\"-\" * 80)\n",
        "diacritics = [c for c in all_chars if 0x0300 <= ord(c) <= 0x036F]\n",
        "if diacritics:\n",
        "    print(f\"Found {len(diacritics)} diacritical marks:\")\n",
        "    for diacritic in sorted(diacritics):\n",
        "        sources = []\n",
        "        if diacritic in dsl_chars:\n",
        "            sources.append(\"DSL\")\n",
        "        if diacritic in mfa_chars:\n",
        "            sources.append(\"MFA\")\n",
        "        if diacritic in model_chars:\n",
        "            sources.append(\"Model\")\n",
        "        print(f\"  '{diacritic}' (U+{ord(diacritic):04X}) - found in: {', '.join(sources)}\")\n",
        "\n",
        "# Suprasegmental marks\n",
        "suprasegmentals = [c for c in all_chars if c in 'ːˌˈ̯͜']\n",
        "if suprasegmentals:\n",
        "    print(f\"\\nFound {len(suprasegmentals)} suprasegmental marks:\")\n",
        "    for sup in sorted(suprasegmentals):\n",
        "        sources = []\n",
        "        if sup in dsl_chars:\n",
        "            sources.append(\"DSL\")\n",
        "        if sup in mfa_chars:\n",
        "            sources.append(\"MFA\")\n",
        "        if sup in model_chars:\n",
        "            sources.append(\"Model\")\n",
        "        print(f\"  '{sup}' (U+{ord(sup):04X}) - found in: {', '.join(sources)}\")\n",
        "\n",
        "print(\"\\n\\nRecommendations:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"1. Unique symbols that are not found elsewhere:\")\n",
        "if only_dsl:\n",
        "    print(f\"   - DSL: {len(only_dsl)} symbols - decide: ignore or map\")\n",
        "if only_mfa:\n",
        "    print(f\"   - MFA: {len(only_mfa)} symbols - decide: ignore or map\")\n",
        "if only_model:\n",
        "    print(f\"   - Model: {len(only_model)} symbols - decide: ignore or map\")\n",
        "\n",
        "print(\"\\n2. Symbol variants (e.g., different 'a', 'g', 'r'):\")\n",
        "print(\"   - Need to decide which variants to use for normalization\")\n",
        "print(\"   - Important: do not simplify close but different phonemes\")\n",
        "\n",
        "print(\"\\n3. Special symbols (diacritics, suprasegmentals):\")\n",
        "print(\"   - Decide how to handle: keep or remove\")\n",
        "print(\"   - Note that some may be important for phoneme distinction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Creating Unified Phoneme Normalization Table\n",
        "\n",
        "This cell creates a unified normalization table that will be used across all project modules to synchronize phoneme extraction from dictionaries and the model.\n",
        "\n",
        "**Normalization Strategy:**\n",
        "- **Unicode normalization**: g → ɡ (only mandatory mapping)\n",
        "- **Diacritics and special symbols**: keep only those present in the model\n",
        "- **Affricates**: expand into phoneme sequences\n",
        "- **Phonemes**: do not map different phonemes, even if they are close (a/ɑ/ɐ, r/ɾ/ʁ, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "9. CREATING UNIFIED PHONEME NORMALIZATION TABLE\n",
            "================================================================================\n",
            "\n",
            "✓ Таблица нормализации создана и сохранена в: /Volumes/SSanDisk/SpeechRec-German-diagnostic/phoneme_normalization_table.json\n",
            "\n",
            "Статистика:\n",
            "  - Фонемных маппингов: 1\n",
            "  - Диакритик (оставить): 6\n",
            "  - Диакритик (удалить): 6\n",
            "  - Suprasegmentals (keep): 1\n",
            "  - Suprasegmentals (remove): 4\n",
            "  - Characters to remove from dictionaries: 31\n",
            "  - Characters only in model: 46\n",
            "  - Model inventory size: 106\n",
            "\n",
            "================================================================================\n",
            "DETAILED DECISION OUTPUT\n",
            "================================================================================\n",
            "\n",
            "1. Phoneme mapping (Unicode normalization):\n",
            "   'g' (U+0067) → 'ɡ' (U+0261)\n",
            "\n",
            "2. Diacritical marks:\n",
            "   ✓ '̃' (U+0303) - keep: Present in model and dictionaries\n",
            "   ✗ '̆' (U+0306) - remove: Not in model - will be removed from dictionaries\n",
            "   ✓ '̊' (U+030A) - keep: Present in model (may be used in recognition)\n",
            "   ✗ '̍' (U+030D) - remove: Not in model - will be removed from dictionaries\n",
            "   ✓ '̝' (U+031D) - keep: Present in model (may be used in recognition)\n",
            "   ✓ '̞' (U+031E) - keep: Present in model (may be used in recognition)\n",
            "   ✗ '̥' (U+0325) - remove: Not in model - will be removed from dictionaries\n",
            "   ✓ '̩' (U+0329) - keep: Present in model and dictionaries\n",
            "   ✓ '̪' (U+032A) - keep: Present in model (may be used in recognition)\n",
            "   ✗ '̯' (U+032F) - remove: Not in model - will be removed from dictionaries\n",
            "   ✗ '͜' (U+035C) - remove: Not in model - will be removed from dictionaries\n",
            "   ✗ '͡' (U+0361) - remove: Not in model - will be removed from dictionaries\n",
            "\n",
            "3. Suprasegmental marks:\n",
            "   ✗ 'ˈ' (U+02C8) - remove: Not in model - will be removed from dictionaries\n",
            "   ✗ 'ˌ' (U+02CC) - remove: Not in model - will be removed from dictionaries\n",
            "   ✓ 'ː' (U+02D0) - keep: Present in model and dictionaries\n",
            "   ✗ '̯' (U+032F) - remove: Not in model - will be removed from dictionaries\n",
            "   ✗ '͜' (U+035C) - remove: Not in model - will be removed from dictionaries\n",
            "\n",
            "4. Affricates (expansion):\n",
            "   't͡s' → 't s'\n",
            "   'd͡ʒ' → 'd ʒ'\n",
            "   't͜s' → 't s'\n",
            "   'd͜ʒ' → 'd ʒ'\n",
            "   'pf' → 'p f'\n",
            "   'ts' → 't s'\n",
            "\n",
            "5. Phonemes preserving distinctions (NOT mapped):\n",
            "   vowels:\n",
            "     - a (U+0061)\n",
            "     - ɑ (U+0251) - open back unrounded\n",
            "     - ɐ (U+0250) - near-open central\n",
            "   e_variants:\n",
            "     - e (U+0065)\n",
            "     - ɛ (U+025B) - open-mid front\n",
            "     - ɜ (U+025C) - open-mid central\n",
            "   i_variants:\n",
            "     - i (U+0069)\n",
            "     - ɪ (U+026A) - near-close near-front\n",
            "   u_variants:\n",
            "     - u (U+0075)\n",
            "     - ʊ (U+028A) - near-close near-back\n",
            "   o_variants:\n",
            "     - o (U+006F)\n",
            "     - ɔ (U+0254) - open-mid back\n",
            "   r_variants:\n",
            "     - r (U+0072) - alveolar trill\n",
            "     - ɾ (U+027E) - alveolar tap\n",
            "     - ʁ (U+0281) - uvular fricative\n",
            "\n",
            "6. Characters to remove from dictionaries (31):\n",
            "   'E' (U+0045) - in: DSL\n",
            "   'ɘ' (U+0258) - in: DSL\n",
            "   '̆' (U+0306) - in: DSL\n",
            "   '̯' (U+032F) - in: DSL\n",
            "   '͜' (U+035C) - in: DSL\n",
            "   'ʀ' (U+0280) - in: DSL\n",
            "   'ˑ' (U+02D1) - in: DSL\n",
            "   'ĭ' (U+012D) - in: DSL\n",
            "   '…' (U+2026) - in: DSL\n",
            "   'O' (U+004F) - in: DSL\n",
            "   'ˌ' (U+02CC) - in: DSL\n",
            "   'ã' (U+00E3) - in: DSL\n",
            "   ''' (U+0027) - in: DSL\n",
            "   '͡' (U+0361) - in: DSL\n",
            "   'g' (U+0067) - in: DSL\n",
            "   'õ' (U+00F5) - in: DSL\n",
            "   'F' (U+0046) - in: DSL\n",
            "   '̥' (U+0325) - in: DSL\n",
            "   'D' (U+0044) - in: DSL\n",
            "   'ʏ' (U+028F) - in: DSL, MFA\n",
            "   ... and 11 more characters\n",
            "\n",
            "================================================================================\n",
            "✓ Normalization table ready for use in the project!\n",
            "================================================================================\n",
            "\n",
            "Usage in code:\n",
            "  import json\n",
            "  with open('phoneme_normalization_table.json', 'r', encoding='utf-8') as f:\n",
            "      normalization = json.load(f)\n",
            "  \n",
            "  # Apply phoneme mapping\n",
            "  for from_char, to_char in normalization['phoneme_mapping'].items():\n",
            "      text = text.replace(from_char, to_char)\n",
            "  \n",
            "  # Remove diacritics not in model\n",
            "  for char, info in normalization['diacritics'].items():\n",
            "      if info['decision'] == 'remove':\n",
            "          text = text.replace(char, '')\n"
          ]
        }
      ],
      "source": [
        "# Create unified phoneme normalization table\n",
        "print(\"=\" * 80)\n",
        "print(\"9. CREATING UNIFIED PHONEME NORMALIZATION TABLE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Phoneme mapping (Unicode normalization)\n",
        "# Only mandatory mapping: g → ɡ\n",
        "phoneme_mapping = {\n",
        "    'g': 'ɡ',  # U+0067 → U+0261 (LATIN SMALL LETTER G → IPA SMALL LETTER G)\n",
        "}\n",
        "\n",
        "# 2. Diacritical marks: decision (keep/remove)\n",
        "# Rule: keep only those present in the model\n",
        "diacritics_decision = {}\n",
        "\n",
        "# Diacritical marks from analysis\n",
        "diacritics_list = [\n",
        "    ('̃', 0x0303, 'COMBINING TILDE'),\n",
        "    ('̆', 0x0306, 'COMBINING BREVE'),\n",
        "    ('̊', 0x030A, 'COMBINING RING ABOVE'),\n",
        "    ('̍', 0x030D, 'COMBINING VERTICAL LINE ABOVE'),\n",
        "    ('̝', 0x031D, 'COMBINING UP TACK BELOW'),\n",
        "    ('̞', 0x031E, 'COMBINING DOWN TACK BELOW'),\n",
        "    ('̥', 0x0325, 'COMBINING RING BELOW'),\n",
        "    ('̩', 0x0329, 'COMBINING VERTICAL LINE BELOW'),\n",
        "    ('̪', 0x032A, 'COMBINING BRIDGE BELOW'),\n",
        "    ('̯', 0x032F, 'COMBINING INVERTED BREVE BELOW'),\n",
        "    ('͜', 0x035C, 'COMBINING DOUBLE BREVE BELOW'),\n",
        "    ('͡', 0x0361, 'COMBINING DOUBLE INVERTED BREVE'),\n",
        "]\n",
        "\n",
        "for char, code, name in diacritics_list:\n",
        "    in_model = char in model_chars\n",
        "    in_dsl = char in dsl_chars\n",
        "    in_mfa = char in mfa_chars\n",
        "    in_dicts = in_dsl or in_mfa\n",
        "    \n",
        "    # Decision: keep only if present in model\n",
        "    decision = \"keep\" if in_model else \"remove\"\n",
        "    reason = \"\"\n",
        "    if in_model and in_dicts:\n",
        "        reason = \"Present in model and dictionaries\"\n",
        "    elif in_model:\n",
        "        reason = \"Present in model (may be used in recognition)\"\n",
        "    else:\n",
        "        reason = \"Not in model - will be removed from dictionaries\"\n",
        "    \n",
        "    diacritics_decision[char] = {\n",
        "        \"unicode\": f\"U+{code:04X}\",\n",
        "        \"name\": name,\n",
        "        \"in_model\": in_model,\n",
        "        \"in_dsl\": in_dsl,\n",
        "        \"in_mfa\": in_mfa,\n",
        "        \"decision\": decision,\n",
        "        \"reason\": reason\n",
        "    }\n",
        "\n",
        "# 3. Suprasegmental marks: decision (keep/remove)\n",
        "suprasegmentals_decision = {}\n",
        "\n",
        "suprasegmentals_list = [\n",
        "    ('ˈ', 0x02C8, 'MODIFIER LETTER PRIMARY STRESS'),\n",
        "    ('ˌ', 0x02CC, 'MODIFIER LETTER SECONDARY STRESS'),\n",
        "    ('ː', 0x02D0, 'MODIFIER LETTER TRIANGULAR COLON'),\n",
        "    ('̯', 0x032F, 'COMBINING INVERTED BREVE BELOW'),  # also a diacritic\n",
        "    ('͜', 0x035C, 'COMBINING DOUBLE BREVE BELOW'),  # also a diacritic\n",
        "]\n",
        "\n",
        "for char, code, name in suprasegmentals_list:\n",
        "    in_model = char in model_chars\n",
        "    in_dsl = char in dsl_chars\n",
        "    in_mfa = char in mfa_chars\n",
        "    in_dicts = in_dsl or in_mfa\n",
        "    \n",
        "    # Decision: keep only if present in model\n",
        "    decision = \"keep\" if in_model else \"remove\"\n",
        "    reason = \"\"\n",
        "    if in_model and in_dicts:\n",
        "        reason = \"Present in model and dictionaries\"\n",
        "    elif in_model:\n",
        "        reason = \"Present in model (may be used in recognition)\"\n",
        "    else:\n",
        "        reason = \"Not in model - will be removed from dictionaries\"\n",
        "    \n",
        "    suprasegmentals_decision[char] = {\n",
        "        \"unicode\": f\"U+{code:04X}\",\n",
        "        \"name\": name,\n",
        "        \"in_model\": in_model,\n",
        "        \"in_dsl\": in_dsl,\n",
        "        \"in_mfa\": in_mfa,\n",
        "        \"decision\": decision,\n",
        "        \"reason\": reason\n",
        "    }\n",
        "\n",
        "# 4. Affricates and composite symbols: expansion rules\n",
        "# If model doesn't use ligatures (͡, ͜), expand into sequence\n",
        "affricates_expansion = {\n",
        "    't͡s': 't s',  # or 'ts' if model supports it\n",
        "    'd͡ʒ': 'd ʒ',  # or 'dʒ' if model supports it\n",
        "    't͜s': 't s',\n",
        "    'd͜ʒ': 'd ʒ',\n",
        "    'pf': 'p f',  # if expansion needed\n",
        "    'ts': 't s',  # if expansion needed\n",
        "}\n",
        "\n",
        "# 5. Phonemes that should NOT be mapped (preserve distinctions)\n",
        "# These phonemes are phonologically distinct and should remain separate\n",
        "phonemes_preserve_distinctions = {\n",
        "    'vowels': {\n",
        "        'a': 'a (U+0061)',\n",
        "        'ɑ': 'ɑ (U+0251) - open back unrounded',\n",
        "        'ɐ': 'ɐ (U+0250) - near-open central',\n",
        "    },\n",
        "    'e_variants': {\n",
        "        'e': 'e (U+0065)',\n",
        "        'ɛ': 'ɛ (U+025B) - open-mid front',\n",
        "        'ɜ': 'ɜ (U+025C) - open-mid central',\n",
        "    },\n",
        "    'i_variants': {\n",
        "        'i': 'i (U+0069)',\n",
        "        'ɪ': 'ɪ (U+026A) - near-close near-front',\n",
        "    },\n",
        "    'u_variants': {\n",
        "        'u': 'u (U+0075)',\n",
        "        'ʊ': 'ʊ (U+028A) - near-close near-back',\n",
        "    },\n",
        "    'o_variants': {\n",
        "        'o': 'o (U+006F)',\n",
        "        'ɔ': 'ɔ (U+0254) - open-mid back',\n",
        "    },\n",
        "    'r_variants': {\n",
        "        'r': 'r (U+0072) - alveolar trill',\n",
        "        'ɾ': 'ɾ (U+027E) - alveolar tap',\n",
        "        'ʁ': 'ʁ (U+0281) - uvular fricative',\n",
        "    },\n",
        "}\n",
        "\n",
        "# 6. Symbols to remove from dictionaries (if not in model)\n",
        "chars_to_remove_from_dicts = []\n",
        "\n",
        "# Characters that are only in dictionaries, but not in model\n",
        "for char in (dsl_chars | mfa_chars) - model_chars:\n",
        "    # Skip ASCII formatting symbols (/, [, ], |, etc.)\n",
        "    if char.isascii() and char in '()[]/|\\\\~':\n",
        "        continue\n",
        "    # Skip spaces and invisible characters\n",
        "    if char.isspace() or ord(char) in [0x200B, 0x2060]:  # ZERO WIDTH SPACE, WORD JOINER\n",
        "        continue\n",
        "    chars_to_remove_from_dicts.append({\n",
        "        \"char\": char,\n",
        "        \"unicode\": f\"U+{ord(char):04X}\",\n",
        "        \"in_dsl\": char in dsl_chars,\n",
        "        \"in_mfa\": char in mfa_chars,\n",
        "        \"reason\": \"Not in model vocabulary - will be removed during normalization\"\n",
        "    })\n",
        "\n",
        "# 7. Model characters not in dictionaries (this is normal - keep them)\n",
        "chars_only_in_model = sorted(list(only_model))\n",
        "\n",
        "# 8. Create final normalization table\n",
        "normalization_table = {\n",
        "    \"version\": \"1.0\",\n",
        "    \"description\": \"Phoneme Normalization & Comparison Strategy for DSL/MFA/G2P → HF phoneme model\",\n",
        "    \"strategy\": {\n",
        "        \"principle\": \"Unicode normalization, not phonological normalization\",\n",
        "        \"key_priority\": \"Dictionaries should not contain symbols that model cannot produce\",\n",
        "        \"phoneme_preservation\": \"Do not merge different phonemes, even if articulatorily similar\"\n",
        "    },\n",
        "    \"phoneme_mapping\": phoneme_mapping,\n",
        "    \"diacritics\": diacritics_decision,\n",
        "    \"suprasegmentals\": suprasegmentals_decision,\n",
        "    \"affricates_expansion\": affricates_expansion,\n",
        "    \"phonemes_preserve_distinctions\": phonemes_preserve_distinctions,\n",
        "    \"chars_to_remove_from_dicts\": chars_to_remove_from_dicts,\n",
        "    \"chars_only_in_model\": chars_only_in_model,\n",
        "    \"model_inventory\": sorted(list(model_chars)),\n",
        "    \"statistics\": {\n",
        "        \"phoneme_mappings\": len(phoneme_mapping),\n",
        "        \"diacritics_keep\": len([d for d in diacritics_decision.values() if d[\"decision\"] == \"keep\"]),\n",
        "        \"diacritics_remove\": len([d for d in diacritics_decision.values() if d[\"decision\"] == \"remove\"]),\n",
        "        \"suprasegmentals_keep\": len([s for s in suprasegmentals_decision.values() if s[\"decision\"] == \"keep\"]),\n",
        "        \"suprasegmentals_remove\": len([s for s in suprasegmentals_decision.values() if s[\"decision\"] == \"remove\"]),\n",
        "        \"chars_to_remove_count\": len(chars_to_remove_from_dicts),\n",
        "        \"chars_only_in_model_count\": len(chars_only_in_model),\n",
        "        \"model_inventory_size\": len(model_chars),\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save normalization table\n",
        "output_path = project_root / \"phoneme_normalization_table.json\"\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(normalization_table, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n✓ Normalization table created and saved to: {output_path}\")\n",
        "print(f\"\\nStatistics:\")\n",
        "print(f\"  - Phoneme mappings: {normalization_table['statistics']['phoneme_mappings']}\")\n",
        "print(f\"  - Diacritics (keep): {normalization_table['statistics']['diacritics_keep']}\")\n",
        "print(f\"  - Diacritics (remove): {normalization_table['statistics']['diacritics_remove']}\")\n",
        "print(f\"  - Suprasegmentals (keep): {normalization_table['statistics']['suprasegmentals_keep']}\")\n",
        "print(f\"  - Suprasegmentals (remove): {normalization_table['statistics']['suprasegmentals_remove']}\")\n",
        "print(f\"  - Characters to remove from dictionaries: {normalization_table['statistics']['chars_to_remove_count']}\")\n",
        "print(f\"  - Characters only in model: {normalization_table['statistics']['chars_only_in_model_count']}\")\n",
        "print(f\"  - Model inventory size: {normalization_table['statistics']['model_inventory_size']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED DECISION OUTPUT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. Phoneme mapping (Unicode normalization):\")\n",
        "for from_char, to_char in phoneme_mapping.items():\n",
        "    print(f\"   '{from_char}' (U+{ord(from_char):04X}) → '{to_char}' (U+{ord(to_char):04X})\")\n",
        "\n",
        "print(\"\\n2. Diacritical marks:\")\n",
        "for char, info in sorted(diacritics_decision.items(), key=lambda x: x[1][\"unicode\"]):\n",
        "    decision_mark = \"✓\" if info[\"decision\"] == \"keep\" else \"✗\"\n",
        "    print(f\"   {decision_mark} '{char}' ({info['unicode']}) - {info['decision']}: {info['reason']}\")\n",
        "\n",
        "print(\"\\n3. Suprasegmental marks:\")\n",
        "for char, info in sorted(suprasegmentals_decision.items(), key=lambda x: x[1][\"unicode\"]):\n",
        "    decision_mark = \"✓\" if info[\"decision\"] == \"keep\" else \"✗\"\n",
        "    print(f\"   {decision_mark} '{char}' ({info['unicode']}) - {info['decision']}: {info['reason']}\")\n",
        "\n",
        "print(\"\\n4. Affricates (expansion):\")\n",
        "for affricate, expansion in affricates_expansion.items():\n",
        "    print(f\"   '{affricate}' → '{expansion}'\")\n",
        "\n",
        "print(\"\\n5. Phonemes preserving distinctions (NOT mapped):\")\n",
        "for category, variants in phonemes_preserve_distinctions.items():\n",
        "    print(f\"   {category}:\")\n",
        "    for char, description in variants.items():\n",
        "        print(f\"     - {description}\")\n",
        "\n",
        "print(f\"\\n6. Characters to remove from dictionaries ({len(chars_to_remove_from_dicts)}):\")\n",
        "for item in chars_to_remove_from_dicts[:20]:  # Show first 20\n",
        "    sources = []\n",
        "    if item[\"in_dsl\"]:\n",
        "        sources.append(\"DSL\")\n",
        "    if item[\"in_mfa\"]:\n",
        "        sources.append(\"MFA\")\n",
        "    print(f\"   '{item['char']}' ({item['unicode']}) - in: {', '.join(sources)}\")\n",
        "if len(chars_to_remove_from_dicts) > 20:\n",
        "    print(f\"   ... and {len(chars_to_remove_from_dicts) - 20} more characters\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✓ Normalization table ready for use in the project!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nUsage in code:\")\n",
        "print(f\"  import json\")\n",
        "print(f\"  with open('{output_path.name}', 'r', encoding='utf-8') as f:\")\n",
        "print(f\"      normalization = json.load(f)\")\n",
        "print(f\"  \")\n",
        "print(f\"  # Apply phoneme mapping\")\n",
        "print(f\"  for from_char, to_char in normalization['phoneme_mapping'].items():\")\n",
        "print(f\"      text = text.replace(from_char, to_char)\")\n",
        "print(f\"  \")\n",
        "print(f\"  # Remove diacritics not in model\")\n",
        "print(f\"  for char, info in normalization['diacritics'].items():\")\n",
        "print(f\"      if info['decision'] == 'remove':\")\n",
        "print(f\"          text = text.replace(char, '')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "8. SAVING RESULTS\n",
            "================================================================================\n",
            "✓ Results saved to: /Volumes/SSanDisk/SpeechRec-German-diagnostic/phoneme_symbols_analysis.json\n",
            "  - Total characters analyzed: 146\n",
            "  - Unique to DSL: 39\n",
            "  - Unique to MFA: 0\n",
            "  - Unique to model: 46\n"
          ]
        }
      ],
      "source": [
        "# Save results to JSON for further analysis\n",
        "print(\"=\" * 80)\n",
        "print(\"8. SAVING RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "results = {\n",
        "    \"dsl_chars\": sorted(list(dsl_chars)),\n",
        "    \"mfa_chars\": sorted(list(mfa_chars)),\n",
        "    \"model_chars\": sorted(list(model_chars)),\n",
        "    \"all_chars\": sorted(list(all_chars)),\n",
        "    \"only_dsl\": sorted(list(only_dsl)),\n",
        "    \"only_mfa\": sorted(list(only_mfa)),\n",
        "    \"only_model\": sorted(list(only_model)),\n",
        "    \"common_all\": sorted(list(common_all)),\n",
        "    \"common_dsl_mfa\": sorted(list(common_dsl_mfa)),\n",
        "    \"common_dsl_model\": sorted(list(common_dsl_model)),\n",
        "    \"common_mfa_model\": sorted(list(common_mfa_model)),\n",
        "    \"statistics\": {\n",
        "        \"dsl_total\": len(dsl_chars),\n",
        "        \"mfa_total\": len(mfa_chars),\n",
        "        \"model_total\": len(model_chars),\n",
        "        \"all_total\": len(all_chars),\n",
        "        \"only_dsl_count\": len(only_dsl),\n",
        "        \"only_mfa_count\": len(only_mfa),\n",
        "        \"only_model_count\": len(only_model),\n",
        "        \"common_all_count\": len(common_all),\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add Unicode code information\n",
        "results[\"char_info\"] = {}\n",
        "for char in all_chars:\n",
        "    results[\"char_info\"][char] = {\n",
        "        \"unicode\": f\"U+{ord(char):04X}\",\n",
        "        \"unicode_code\": ord(char),\n",
        "        \"in_dsl\": char in dsl_chars,\n",
        "        \"in_mfa\": char in mfa_chars,\n",
        "        \"in_model\": char in model_chars,\n",
        "    }\n",
        "\n",
        "output_path = project_root / \"phoneme_symbols_analysis.json\"\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✓ Results saved to: {output_path}\")\n",
        "print(f\"  - Total characters analyzed: {len(all_chars)}\")\n",
        "print(f\"  - Unique to DSL: {len(only_dsl)}\")\n",
        "print(f\"  - Unique to MFA: {len(only_mfa)}\")\n",
        "print(f\"  - Unique to model: {len(only_model)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "speechrec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
