{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Boundary Forced Alignment Test\n",
    "\n",
    "This notebook tests the MFA-based word boundary insertion algorithm.\n",
    "\n",
    "## Goals:\n",
    "1. Test MFA alignment on sample audio files\n",
    "2. Compare OLD (proportional) vs NEW (MFA-based) word boundary insertion\n",
    "3. Verify that phonemes are preserved at word boundaries\n",
    "4. Evaluate boundary accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules.mfa_aligner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mabsolute()\u001b[38;5;241m.\u001b[39mparent))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmfa_aligner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_mfa_aligner\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mword_boundary_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m insert_word_boundaries_mfa, insert_word_boundaries\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphoneme_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PhonemeRecognizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules.mfa_aligner'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('.').absolute().parent))\n",
    "\n",
    "from modules.mfa_aligner import get_mfa_aligner\n",
    "from modules.word_boundary_utils import insert_word_boundaries_mfa, insert_word_boundaries\n",
    "from modules.phoneme_recognition import PhonemeRecognizer\n",
    "from modules.g2p_module import get_g2p\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFA aligner initialized!\n",
      "MFA binary: /Volumes/SSanDisk/SpeechRec-German/miniforge/envs/mfa310/bin/mfa\n"
     ]
    }
   ],
   "source": [
    "# Initialize MFA aligner with explicit path\n",
    "mfa_aligner = get_mfa_aligner(\n",
    "    mfa_bin=\"/Volumes/SSanDisk/SpeechRec-German/miniforge/envs/mfa310/bin/mfa\",\n",
    "    mfa_dict=\"german_mfa\",\n",
    "    mfa_model=\"german_mfa\"\n",
    ")\n",
    "\n",
    "print(\"MFA aligner initialized!\")\n",
    "print(f\"MFA binary: {mfa_aligner.mfa_bin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 test records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>audio_path_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17466</th>\n",
       "      <td>Kannst du programmieren?</td>\n",
       "      <td>/Volumes/SSanDisk/audio_data/data_wav/TV-2021....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34962</th>\n",
       "      <td>nichts desto trotz ist das jedoch ein schönes ...</td>\n",
       "      <td>/Volumes/SSanDisk/audio_data/data_wav/TV-2022....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>Verschiedene Karrierewege sind denkbar.</td>\n",
       "      <td>/Volumes/SSanDisk/audio_data/data_wav/TV-2021....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>Aber Fotosynthese mit F sieht schon komisch aus.</td>\n",
       "      <td>/Volumes/SSanDisk/audio_data/data_wav/TV-2021....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>Manchmal muss man einfach ein bisschen Quatsch...</td>\n",
       "      <td>/Volumes/SSanDisk/audio_data/data_wav/TV-2021....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "17466                           Kannst du programmieren?   \n",
       "34962  nichts desto trotz ist das jedoch ein schönes ...   \n",
       "5561             Verschiedene Karrierewege sind denkbar.   \n",
       "10405   Aber Fotosynthese mit F sieht schon komisch aus.   \n",
       "7516   Manchmal muss man einfach ein bisschen Quatsch...   \n",
       "\n",
       "                                        audio_path_fixed  \n",
       "17466  /Volumes/SSanDisk/audio_data/data_wav/TV-2021....  \n",
       "34962  /Volumes/SSanDisk/audio_data/data_wav/TV-2022....  \n",
       "5561   /Volumes/SSanDisk/audio_data/data_wav/TV-2021....  \n",
       "10405  /Volumes/SSanDisk/audio_data/data_wav/TV-2021....  \n",
       "7516   /Volumes/SSanDisk/audio_data/data_wav/TV-2021....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a few examples from metadata\n",
    "df = pd.read_csv('/Volumes/SSanDisk/SpeechRec-German-diagnostic/data/dictionaries/metadata_wav_clean_hochdeutsch.csv')\n",
    "\n",
    "# Fix audio paths\n",
    "df['audio_path_fixed'] = df['audio_wav_path'].str.replace(\n",
    "    '/Volumes/SSanDisk/SpeechRec-German/',\n",
    "    '/Volumes/SSanDisk/audio_data/'\n",
    ")\n",
    "\n",
    "# Sample 10 records for testing\n",
    "test_df = df.sample(n=10, random_state=42)\n",
    "print(f\"Loaded {len(test_df)} test records\")\n",
    "test_df[['text', 'audio_path_fixed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Kannst du programmieren?\n",
      "Audio: /Volumes/SSanDisk/audio_data/data_wav/TV-2021.02-Neutral/4aeeae88-0777-2c8c-5c93-2e844a462e49---6e5325ee54e5d4a685fb3ba30c0efa69.wav\n",
      "\n",
      "MFA phonemes (18):\n",
      "  kʰ        0.0 -    80.0 ms\n",
      "  a        80.0 -   130.0 ms\n",
      "  n       130.0 -   180.0 ms\n",
      "  s       180.0 -   260.0 ms\n",
      "  t       260.0 -   300.0 ms\n",
      "  d       300.0 -   310.0 ms\n",
      "  uː      310.0 -   370.0 ms\n",
      "  p       370.0 -   490.0 ms\n",
      "  ʁ       490.0 -   500.0 ms\n",
      "  ɔ       500.0 -   560.0 ms\n",
      "  ɡ       560.0 -   680.0 ms\n",
      "  ʁ       680.0 -   690.0 ms\n",
      "  a       690.0 -   740.0 ms\n",
      "  m       740.0 -   800.0 ms\n",
      "  iː      800.0 -   890.0 ms\n",
      "  ʁ       890.0 -   970.0 ms\n",
      "  ə       970.0 -  1020.0 ms\n",
      "  n      1020.0 -  1130.0 ms\n"
     ]
    }
   ],
   "source": [
    "# Test MFA alignment on first record\n",
    "test_record = test_df.iloc[0]\n",
    "\n",
    "print(f\"Text: {test_record['text']}\")\n",
    "print(f\"Audio: {test_record['audio_path_fixed']}\")\n",
    "\n",
    "# Get MFA alignment\n",
    "try:\n",
    "    mfa_result = mfa_aligner.align_single_file(\n",
    "        test_record['audio_path_fixed'],\n",
    "        test_record['text']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nMFA phonemes ({len(mfa_result)}):\")\n",
    "    for p in mfa_result[:20]:\n",
    "        print(f\"  {p['phoneme']:5s} {p['start_ms']:7.1f} - {p['end_ms']:7.1f} ms\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: facebook/wav2vec2-xlsr-53-espeak-cv-ft\n",
      "Model loaded on device: mps\n",
      "Vocabulary size: 392\n",
      "Sample IPA phonemes in vocab: ['n', 's', 't', 'ə', 'l', 'a', 'i', 'k', 'd', 'm', 'ɛ', 'ɾ', 'e', 'ɪ', 'p', 'o', 'ɐ', 'z', 'ð', 'f']\n",
      "\n",
      "================================================================================\n",
      "Text: Kannst du programmieren?\n",
      "Loaded 143249 words from lexicon cache in 0.41 seconds.\n",
      "Loaded 278343 words from DSL lexicon cache in 0.72 seconds.\n",
      "Loaded phoneme normalization table from /Volumes/SSanDisk/SpeechRec-German-diagnostic/phoneme_normalization_table.json\n",
      "  - Phoneme mappings: 4\n",
      "  - Diacritics to remove: 6\n",
      "  - Suprasegmentals to remove: 4\n",
      "  - Invalid patterns: 4\n",
      "  - Characters to remove: 34\n",
      "\n",
      "Expected:   k a n s t || ː || p ʀ o ɡ ʀ a m iː ʀ ə n...\n",
      "OLD method: k a n s t || uː || p ɾ oː ɡ ɾ a m iː r ə n...\n",
      "NEW method: k a n s || t || uː p ɾ oː ɡ ɾ a m iː r ə n...\n",
      "\n",
      "Boundaries:\n",
      "  Expected: 2 at positions [5, 7]...\n",
      "  OLD:      2 at positions [5, 7]...\n",
      "  NEW:      2 at positions [4, 6]...\n",
      "\n",
      "================================================================================\n",
      "Text: nichts desto trotz ist das jedoch ein schönes zusammentreffen.\n",
      "\n",
      "Expected:   n ɪ ç t s || d ɛ s t o || t ʁ ɔ t s || ɪ s t || d a s || j eː d ɔ x || ɛ ɪ n || ʃ øː n ə s || t s uː z a m m ɛ...\n",
      "OLD method: n ɪ ç t || ts d ɛ s || t oː t ɾ || ɔ ts ɪ || s t d || a s j eː || d ɔ x || aɪ n ʃ yː || n ə s ts uː z a m ə n t ɾ ɛ...\n",
      "NEW method: n ɪ ç t ts d ɛ s || t oː t ɾ || ɔ ts ɪ s t d || a s j eː || d || ɔ x aɪ n || ʃ || yː n ə s ts || uː z a m ə n t ɾ ɛ...\n",
      "\n",
      "Boundaries:\n",
      "  Expected: 8 at positions [5, 11, 17, 21, 25]...\n",
      "  OLD:      8 at positions [4, 9, 14, 18, 22]...\n",
      "  NEW:      8 at positions [8, 13, 20, 25, 27]...\n",
      "\n",
      "================================================================================\n",
      "Text: Verschiedene Karrierewege sind denkbar.\n",
      "\n",
      "Expected:   f ɛː ɐ ʃ iː d ə n ə || kʰ a ɐ j eː ʁ ə v eː ɡ ə || z ɪ n t || d ɛ ŋ k b a ɽ...\n",
      "OLD method: ɛ ɾ ʃ iː d ə n ə || k a r j eː r ə v eː ɡ || ə z ɪ n || t d ɛ ŋ k b ɑː...\n",
      "NEW method: ɛ ɾ ʃ iː d ə n || ə k a r j eː r ə v eː ɡ ə || z ɪ n t d || ɛ ŋ k b ɑː...\n",
      "\n",
      "Boundaries:\n",
      "  Expected: 3 at positions [9, 21, 26]...\n",
      "  OLD:      3 at positions [8, 19, 24]...\n",
      "  NEW:      3 at positions [7, 20, 26]...\n"
     ]
    }
   ],
   "source": [
    "# Test full pipeline: OLD vs NEW method\n",
    "recognizer = PhonemeRecognizer()\n",
    "g2p = get_g2p()\n",
    "\n",
    "for i, row in test_df.head(3).iterrows():\n",
    "    text = row['text']\n",
    "    audio_path = row['audio_path_fixed']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    \n",
    "    try:\n",
    "        # Get expected phonemes\n",
    "        expected_dict = g2p.process_sentence(text)\n",
    "        expected_phonemes = [p.get('phoneme', '') for p in expected_dict if p.get('phoneme')]\n",
    "        \n",
    "        # Get recognized phonemes\n",
    "        logits, _ = recognizer.recognize_phonemes(audio_path)\n",
    "        recognized_str = recognizer.decode_phonemes(logits)\n",
    "        recognized_phonemes = recognized_str.split()\n",
    "        \n",
    "        # OLD method (proportional)\n",
    "        old_result = insert_word_boundaries(text, expected_phonemes, recognized_phonemes)\n",
    "        \n",
    "        # NEW method (MFA)\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        audio_duration = waveform.shape[1] / sr\n",
    "        \n",
    "        new_result = insert_word_boundaries_mfa(\n",
    "            text=text,\n",
    "            recognized_phonemes=recognized_phonemes,\n",
    "            audio_path=audio_path,\n",
    "            logits=logits,\n",
    "            audio_duration=audio_duration,\n",
    "            mfa_aligner=mfa_aligner\n",
    "        )\n",
    "        \n",
    "        # Compare\n",
    "        print(f\"\\nExpected:   {' '.join(expected_phonemes[:50])}...\")\n",
    "        print(f\"OLD method: {' '.join(old_result[:50])}...\")\n",
    "        print(f\"NEW method: {' '.join(new_result[:50])}...\")\n",
    "        \n",
    "        # Count || positions\n",
    "        expected_boundaries = [i for i, p in enumerate(expected_phonemes) if p == '||']\n",
    "        old_boundaries = [i for i, p in enumerate(old_result) if p == '||']\n",
    "        new_boundaries = [i for i, p in enumerate(new_result) if p == '||']\n",
    "        \n",
    "        print(f\"\\nBoundaries:\")\n",
    "        print(f\"  Expected: {len(expected_boundaries)} at positions {expected_boundaries[:5]}...\")\n",
    "        print(f\"  OLD:      {len(old_boundaries)} at positions {old_boundaries[:5]}...\")\n",
    "        print(f\"  NEW:      {len(new_boundaries)} at positions {new_boundaries[:5]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Boundary Accuracy Results:\n",
      "  OLD method: 89.58% (mean)\n",
      "  NEW method: 71.33% (mean)\n",
      "\n",
      "  OLD method: 100.00% (median)\n",
      "  NEW method: 69.05% (median)\n"
     ]
    }
   ],
   "source": [
    "# Calculate boundary accuracy\n",
    "def calculate_boundary_accuracy(expected, predicted, tolerance=1):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of word boundary positions.\n",
    "    \n",
    "    Args:\n",
    "        expected: List with || markers\n",
    "        predicted: List with || markers\n",
    "        tolerance: Allowed position difference (±tolerance)\n",
    "    \n",
    "    Returns:\n",
    "        Accuracy score (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    expected_positions = set(i for i, p in enumerate(expected) if p == '||')\n",
    "    predicted_positions = set(i for i, p in enumerate(predicted) if p == '||')\n",
    "    \n",
    "    if not expected_positions:\n",
    "        return 1.0 if not predicted_positions else 0.0\n",
    "    \n",
    "    # Allow ±tolerance position tolerance\n",
    "    correct = 0\n",
    "    for exp_pos in expected_positions:\n",
    "        if any(abs(exp_pos - pred_pos) <= tolerance for pred_pos in predicted_positions):\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(expected_positions)\n",
    "\n",
    "# Test on all records\n",
    "old_accuracies = []\n",
    "new_accuracies = []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    text = row['text']\n",
    "    audio_path = row['audio_path_fixed']\n",
    "    \n",
    "    try:\n",
    "        # Get expected phonemes\n",
    "        expected_dict = g2p.process_sentence(text)\n",
    "        expected_phonemes = [p.get('phoneme', '') for p in expected_dict if p.get('phoneme')]\n",
    "        \n",
    "        # Get recognized phonemes\n",
    "        logits, _ = recognizer.recognize_phonemes(audio_path)\n",
    "        recognized_str = recognizer.decode_phonemes(logits)\n",
    "        recognized_phonemes = recognized_str.split()\n",
    "        \n",
    "        # OLD method\n",
    "        old_result = insert_word_boundaries(text, expected_phonemes, recognized_phonemes)\n",
    "        old_acc = calculate_boundary_accuracy(expected_phonemes, old_result)\n",
    "        old_accuracies.append(old_acc)\n",
    "        \n",
    "        # NEW method\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        audio_duration = waveform.shape[1] / sr\n",
    "        \n",
    "        new_result = insert_word_boundaries_mfa(\n",
    "            text=text,\n",
    "            recognized_phonemes=recognized_phonemes,\n",
    "            audio_path=audio_path,\n",
    "            logits=logits,\n",
    "            audio_duration=audio_duration,\n",
    "            mfa_aligner=mfa_aligner\n",
    "        )\n",
    "        new_acc = calculate_boundary_accuracy(expected_phonemes, new_result)\n",
    "        new_accuracies.append(new_acc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error on record {i}: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Boundary Accuracy Results:\")\n",
    "print(f\"  OLD method: {np.mean(old_accuracies):.2%} (mean)\")\n",
    "print(f\"  NEW method: {np.mean(new_accuracies):.2%} (mean)\")\n",
    "print(f\"\\n  OLD method: {np.median(old_accuracies):.2%} (median)\")\n",
    "print(f\"  NEW method: {np.median(new_accuracies):.2%} (median)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
